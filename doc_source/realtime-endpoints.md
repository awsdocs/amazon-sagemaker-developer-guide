# Real\-time inference<a name="realtime-endpoints"></a>

Real\-time inference is ideal for inference workloads where you have real\-time, interactive, low latency requirements\. You can deploy your model to SageMaker hosting services and get an endpoint that can be used for inference\. These endpoints are fully managed, support autoscaling \(see [Automatically Scale Amazon SageMaker Models](endpoint-auto-scaling.md)\), and can be deployed in multiple [Availability Zones](instance-types-az.md)\.

**Topics**
+ [Hosting options](realtime-endpoints-options.md)
+ [Automatically Scale Amazon SageMaker Models](endpoint-auto-scaling.md)
+ [Host instance storage volumes](host-instance-storage.md)
+ [Safely update models in production](model-ab-testing.md)
+ [Deployment guardrails](deployment-guardrails.md)
+ [Best practices](best-practices.md)
+ [Monitor models for data and model quality, bias, and explainability](model-monitor.md)
+ [Invoke real\-time endpoints](realtime-endpoints-test-endpoints.md)